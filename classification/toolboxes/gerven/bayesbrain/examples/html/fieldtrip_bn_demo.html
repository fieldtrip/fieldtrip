
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML is auto-generated from an M-file.
To make changes, update the M-file and republish this document.
      --><title>Using Bayesian networks together with FieldTrip data</title><meta name="generator" content="MATLAB 7.9"><meta name="date" content="2009-10-29"><meta name="m-file" content="fieldtrip_bn_demo"><style type="text/css">

body {
  background-color: white;
  margin:10px;
}

h1 {
  color: #990000; 
  font-size: x-large;
}

h2 {
  color: #990000;
  font-size: medium;
}

/* Make the text shrink to fit narrow windows, but not stretch too far in 
wide windows. */ 
p,h1,h2,div.content div {
  max-width: 600px;
  /* Hack for IE6 */
  width: auto !important; width: 600px;
}

pre.codeinput {
  background: #EEEEEE;
  padding: 10px;
}
@media print {
  pre.codeinput {word-wrap:break-word; width:100%;}
} 

span.keyword {color: #0000FF}
span.comment {color: #228B22}
span.string {color: #A020F0}
span.untermstring {color: #B20000}
span.syscmd {color: #B28C00}

pre.codeoutput {
  color: #666666;
  padding: 10px;
}

pre.error {
  color: red;
}

p.footer {
  text-align: right;
  font-size: xx-small;
  font-weight: lighter;
  font-style: italic;
  color: gray;
}

  </style></head><body><div class="content"><h1>Using Bayesian networks together with FieldTrip data</h1><!--introduction--><p>This example demonstrates how to use neuroimaging data obtained from FieldTrip together with the neurogm toolbox. In the example, we make use of covert attention data of one subject that has already been frequency analyzed. Note that this is trial based data so we can build finite size models that capture behaviour within a trial.</p><p>The data consists of 7 different frequencies at 274 channels at time points [-0.5 0 0.5 1 1.5 2 2.5]. We can expect evoked response after the cue and alpha modulation after about 1 second</p><p>In this particular example, we will construct a standard Bayesian network and demonstrate its use.</p><p>Copyright (C) 2008  Marcel van Gerven</p><!--/introduction--><h2>Contents</h2><div><ul><li><a href="#1">Compare log likelihood of a Bayesian network before/after learning</a></li></ul></div><h2>Compare log likelihood of a Bayesian network before/after learning<a name="1"></a></h2><pre class="codeinput"><span class="keyword">function</span> fieldtrip_bn_demo()
</pre><p>Load frequency data and convert the data to a format that can be used. A Bayesian network is a static model, so we will take out the time data and focus only on the 12 Hz band in two channels in left and right hemisphere.</p><pre class="codeinput">load  <span class="string">covattfrq1</span>;

<span class="comment">% left and right channels</span>
l = find(ismember(left.label,<span class="string">'MLO32'</span>));
r = find(ismember(left.label,<span class="string">'MRO32'</span>));

<span class="comment">% We take the log to make the data better behaved</span>
left = log((squeeze(nan_mean(left.powspctrm(:,[l r],3,:),4))));
right = log((squeeze(nan_mean(right.powspctrm(:,[l r],3,:),4))));
</pre><p>Now we can create a very simple model that consists of one discrete parent (the attention condition) and two continuous children</p><pre class="codeinput">data = [[left ones(size(left,1),1)]; [right 2*ones(size(right,1),1)]];
clear <span class="string">left</span>; clear <span class="string">right</span>;
</pre><pre>Create the random variables; they should follow the data ordering</pre><pre class="codeinput">factors = cell(1,3);
factors{1} = gaussian_cpd(1,[],3,[0; 0],{[]; []},[1; 1]);
factors{2} = gaussian_cpd(2,[],3,[0; 0],{[]; []},[1; 1]);
factors{3} = multinomial_cpd(3,[],[0.5; 0.5]);

<span class="comment">% optionally add names to the factors</span>
factors{1}.name = <span class="string">'MLO32'</span>;
factors{2}.name = <span class="string">'MRO32'</span>;
factors{3}.name = <span class="string">'orientation'</span>;
factors{3}.statenames = {<span class="string">'left attention'</span> <span class="string">'right attention'</span>};
</pre><p>Create simple bayes net</p><pre class="codeinput">bn = bayesnet(factors);
</pre><p>Write graph structure to .ps file (requires installation of GraphViz library)</p><pre class="codeinput">bn.write(<span class="string">'tmpbn'</span>,<span class="string">'dot'</span>,<span class="string">'extension'</span>,<span class="string">'ps'</span>);
</pre><pre class="codeoutput">/bin/bash: dot: command not found
</pre><p>This is what the plot would look like</p><p><img vspace="5" hspace="5" src="fieldtrip_bn_demo_files/tmpbn.jpg" alt=""> </p><p>Log likelihood of this model is pretty low since we did not train parameters</p><pre class="codeinput">bn.loglik(data)
</pre><pre class="codeoutput">
ans =

  -3.6291e+03

</pre><p>Learn parameters from complete data</p><pre class="codeinput">bn = bn.learn_parameters(data);
</pre><p>Log likelihood has increased</p><pre class="codeinput">bn.loglik(data)
</pre><pre class="codeoutput">
ans =

   -2.6150

</pre><p>Plot the estimated prior distributions with continuous ones of the form</p><p><img src="fieldtrip_bn_demo_files/fieldtrip_bn_demo_eq35319.png" alt="$$ \mathcal{N}(x; \mu_c, \sigma_c)$$"></p><pre class="codeinput">subplot(1,3,1);
bn.factors{1}.plot();
legend(<span class="string">'left attention'</span>,<span class="string">'right attention'</span>);
subplot(1,3,2);
bn.factors{2}.plot();
legend(<span class="string">'left attention'</span>,<span class="string">'right attention'</span>);
subplot(1,3,3);
bn.factors{3}.plot();
set(gcf,<span class="string">'Position'</span>,[100 100 1500 400]);
</pre><img vspace="5" hspace="5" src="fieldtrip_bn_demo_files/fieldtrip_bn_demo_01.png" alt=""> <p>Create an inference engine</p><pre class="codeinput">ie = canonical_jtree_ie(bn);
</pre><pre class="codeoutput">triangulating model
constructing potentials
constructing junction tree
computing messages
</pre><p>Add some evidence</p><pre class="codeinput">ie.enter_evidence([nan -59.5 nan]);
</pre><p>Compute marginals</p><pre class="codeinput">m1 = normalize(ie.marginalize(1));
m3 = normalize(ie.marginalize(3));
</pre><p>Plot the marginals after evidence propagation</p><pre class="codeinput">figure
subplot(1,2,1);
m1.plot();
subplot(1,2,2);
m3.plot();
</pre><img vspace="5" hspace="5" src="fieldtrip_bn_demo_files/fieldtrip_bn_demo_02.png" alt=""> <p class="footer"><br>
      Published with MATLAB&reg; 7.9<br></p></div><!--
##### SOURCE BEGIN #####
%% Using Bayesian networks together with FieldTrip data
% This example demonstrates how to use neuroimaging data obtained from FieldTrip
% together with the neurogm toolbox. In the example, we make use of covert
% attention data of one subject that has already been frequency analyzed.
% Note that this is trial based data so we can build finite size models
% that capture behaviour within a trial.
%
% The data consists of 7 different frequencies at 274 channels at time
% points [-0.5 0 0.5 1 1.5 2 2.5]. We can expect evoked response after the
% cue and alpha modulation after about 1 second
%
% In this particular example, we will construct a standard Bayesian network and
% demonstrate its use.
%
% Copyright (C) 2008  Marcel van Gerven
%

%% Compare log likelihood of a Bayesian network before/after learning
function fieldtrip_bn_demo()

%%
% Load frequency data and convert the data to a format that can be used.
% A Bayesian network is a static model, so we will take out the time data
% and focus only on the 12 Hz band in two channels in left and right
% hemisphere.

load  covattfrq1;

% left and right channels
l = find(ismember(left.label,'MLO32'));
r = find(ismember(left.label,'MRO32'));

% We take the log to make the data better behaved
left = log((squeeze(nan_mean(left.powspctrm(:,[l r],3,:),4))));
right = log((squeeze(nan_mean(right.powspctrm(:,[l r],3,:),4))));

%%
% Now we can create a very simple model that consists of one discrete
% parent (the attention condition) and two continuous children
data = [[left ones(size(left,1),1)]; [right 2*ones(size(right,1),1)]];
clear left; clear right;

%%
%  Create the random variables; they should follow the data ordering
factors = cell(1,3);
factors{1} = gaussian_cpd(1,[],3,[0; 0],{[]; []},[1; 1]);
factors{2} = gaussian_cpd(2,[],3,[0; 0],{[]; []},[1; 1]);
factors{3} = multinomial_cpd(3,[],[0.5; 0.5]);

% optionally add names to the factors
factors{1}.name = 'MLO32';
factors{2}.name = 'MRO32';
factors{3}.name = 'orientation';
factors{3}.statenames = {'left attention' 'right attention'};

%%
% Create simple bayes net
bn = bayesnet(factors);

%%
% Write graph structure to .ps file (requires installation of GraphViz
% library)
bn.write('tmpbn','dot','extension','ps');

%% 
% This is what the plot would look like
%
% <<fieldtrip_bn_demo_files/tmpbn.jpg>>

%%
% Log likelihood of this model is pretty low since we did not train
% parameters
bn.loglik(data)

%%
% Learn parameters from complete data
bn = bn.learn_parameters(data);

%%
% Log likelihood has increased
bn.loglik(data)

%%
% Plot the estimated prior distributions with continuous ones of the form
%
% $$ \mathcal{N}(x; \mu_c, \sigma_c)$$
%
        
subplot(1,3,1);
bn.factors{1}.plot();
legend('left attention','right attention');
subplot(1,3,2);
bn.factors{2}.plot();
legend('left attention','right attention');
subplot(1,3,3);
bn.factors{3}.plot();
set(gcf,'Position',[100 100 1500 400]);

%%
% Create an inference engine

ie = canonical_jtree_ie(bn);

%% 
% Add some evidence

ie.enter_evidence([nan -59.5 nan]);

%%
% Compute marginals

m1 = normalize(ie.marginalize(1));
m3 = normalize(ie.marginalize(3));

%% 
% Plot the marginals after evidence propagation

figure
subplot(1,2,1);
m1.plot();
subplot(1,2,2);
m3.plot();

##### SOURCE END #####
--></body></html>